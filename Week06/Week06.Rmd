
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library  
```{r message = F, warning = F}
library(tidyverse)
library(Hmisc)
```

### Read in data  
```{r message = F, warning = F}
library(readxl)
setwd("../Week06")
fname <- "week6_coffee_chains.xlsx"
excel_sheets(fname)
dfStar <- read_excel(fname, 1)
dfTimh <- read_excel(fname, 2)
dfDunk <- read_excel(fname, 3)
```

### Obtain TH locations
```{r}

geocodeAdddress <- function(address) {
  require(RJSONIO)
  url <- "http://maps.google.com/maps/api/geocode/json?address="
  url <- URLencode(paste(url, address, "&sensor=false", sep = ""))
  x <- fromJSON(url, simplify = FALSE)
  if (x$status == "OK") {
    out <- c(x$results[[1]]$geometry$location$lng,
             x$results[[1]]$geometry$location$lat)
  } else {
    cat(paste0(address, "\n"))
    out <- NA
  }
  Sys.sleep(1)  # API only allows 5 requests per second
  out
}

library(ggmap)
TimhUS <- dfTimh %>% 
  rename(ST = state, Country = country, City = city) %>%
  filter(Country == "us") %>% 
  mutate(postal_code = replace(postal_code, 
                               nchar(postal_code) == 4, 
                               paste0("0", postal_code))) %>% 
  mutate(Country = "USA",
         State = openintro::abbr2state(ST),
         address = paste(address, City, ST, postal_code, sep = ", ")) %>% 
  select(Country, address, State, ST, City)

nTimh <- nrow(TimhUS)
loc <- data.frame(Longitude = rep(NA, nTimh), Latitude = rep(NA, nTimh))
for (i in 1: nTimh){
  loc[i,] <- geocodeAdddress(TimhUS[i, "address"])
  cat(paste0(i, "\n"))
}

#cb <- cbind(TimhUS, loc) %>% 
#  filter(is.na(Longitude))
```

### Data Cleaning
```{r fig.width = 10}
library(usmap)
data(statepop)

# Select US Starbucks  
StarUS <- dfStar %>% 
  rename(ST = `State/Province`) %>%
  filter(Country == "US") %>% 
  mutate(State = openintro::abbr2state(ST)) %>% 
  select(Country, State, ST, City, Longitude, Latitude) %>% 
  mutate(Store = "Starbucks")

# Starbucks numbers in each states  
avgStarUS <- StarUS %>% 
  group_by(State) %>% 
  summarise(count = n(), ST = unique(ST)) %>% 
  left_join(statepop, by = c("ST" = "abbr")) %>% 
  mutate(Avg = count/pop_2015 * 1e5) 

# Select US Duckin  
DuckUS <- dfDunk %>% 
  rename(Country = e_country, ST = e_state, City = e_city,
         Longitude = loc_LONG_poly, Latitude = loc_LAT_poly) %>% 
  mutate(State = openintro::abbr2state(ST)) %>% 
  select(Country, State, ST, City, Longitude, Latitude) %>% 
  filter(Country == "USA") %>% 
  mutate(Store = "Dunkin' Donuts")
         
#         Longitude = geocode(address)[0],
#         Latitude = geocode(address)[1])
  
SDUS <- rbind(StarUS, DuckUS)
avgSDUS <- SDUS %>% 
  group_by(State, Store) %>% 
  summarise(count = n(), ST = unique(ST)) %>% 
  left_join(statepop, by = c("ST" = "abbr")) %>% 
  mutate(Avg = count/pop_2015 * 1e5)
```

### Fifty States from `albersusa`
```{r fig.width = 10}
library(albersusa)
us      <- usa_composite()
us_map  <- broom::tidy(us, region = "name")

p <- ggplot() +
  geom_map(data = avgStarUS, aes(fill = Avg, map_id = State),
           color="white", size = 0.01, map = us_map) + 
  scale_fill_distiller(name = "Number", palette = "Spectral") +
  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
  theme(legend.position=c(.88, .4))+
  ggtitle( "Starbucks Stores per 100, 000 population" ) +
  labs(caption = "Source: US Census Demogrpahic Data 2015")
  
p
```

### Dot Density Map for CONUS
```{r fig.width = 10}
StarCONUS <- filter(StarUS, ST != "HI" & ST != "AK")
avgStarCONUS <- filter(avgStarUS, ST != "HI" & ST != "AK")
 
t <- ggplot() +
  geom_map(data = avgStarCONUS, aes(fill = Avg, map_id = State),
           color="white", size = 0.01, map = us_map) + 
  scale_fill_distiller(name = "Number", palette = "Spectral") +
  geom_point(data = StarCONUS, aes(x = Longitude, y = Latitude), size = 0.04, alpha = 0.1) +

  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
  theme(legend.position=c(.88, .4)) +
  ggtitle( "Starbucks Stores per 100, 000 population" ) +
  labs(caption = "Source: US Census Demogrpahic Data 2015")
t
#t + coord_map("polyconic")
```

### Compare Starbucks and Dunkin' Donuts
```{r fig.width = 10}
StarCONUS <- filter(StarUS, ST != "HI" & ST != "AK")
SDCONUS   <- filter(SDUS, ST != "HI" & ST != "AK")
us_map <- filter(us_map, id !="Hawaii" & id != "Alaska") 

c <- ggplot() +
  geom_map(data = us_map, aes(map_id = id),
           color="#2b2b2b", size = 0.1, fill = NA, map = us_map) + 
  #scale_fill_distiller(name = "Number", palette = "Spectral") +
  geom_point(data = SDCONUS, aes(x = Longitude, y = Latitude, color = Store), 
             size = 0.5, alpha = 0.1) +
  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
#  theme(legend.position = "top")+
  ggtitle( "Starbucks and Dunkin's Donuts Stores" ) +
  labs(caption = "Source: US Census Demogrpahic Data 2015") +
  guides(colour = guide_legend(title = NULL, override.aes = list(size = 3 ))) +
  theme(legend.position=c(.88, .3)) 
c
```

```{r fig.height = 15, fig.width = 10}
library(grid)
library(gridExtra)
grid.arrange(p, t, c, ncol = 1)
```


